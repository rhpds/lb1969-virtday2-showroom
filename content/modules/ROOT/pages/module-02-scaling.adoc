= Real world scaling scenario

//, new capacity demands (45 minutes)

== Performance and Observability

=== Examine Load on Virtual Guests

=== Example graphs, logs, and alerts.

==== Node Graphs

Now lets look at the metrics for the Nodes.

. Under *Compute* Click on *Nodes*. From This view you can see the Node status and role.
+
image::day-to-day/node_list.png[link=self, window=blank, width=100%]
+
. Click on one of the nodes.
+
image::day-to-day/node_example.png[link=self, window=blank, width=100%]
+
. You will see the Utilization. You can select if you want to see 1, 6 or 24 hours.

==== Virtal Machine Graphs

. Click on *Workloads* > *Deployments* > *loadmaker*. Ensure you are in Project: *windows-vms*.
+
image::day-to-day/select_loadmaker.png[link=self, window=blank, width=100%]
+
. You should see 1 Pod under the Deployment Details tab.
+
image::day-to-day/show_num_pod.png[link=self, window=blank, width=100%]
+
. Click on *Environment* tab
+
image::day-to-day/lm_pod_config.png[link=self, window=blank, width=100%]
+
. In *Virtualization* > *VirtualMachine* Select *windows-vms* project to show *winweb01*, *winweb02* and *database*. You should only see *database* and *winweb01* powered on. Power on them if needed.

. Click on *winweb01* 
+
image::day-to-day/ob_select_vm.png[link=self, window=blank, width=100%]
+
. On the main page of the VM there is a utilization section that show the basic status of the VM updated every 15 seconds.
- Each of the line graphs are clickable.
- Note: CPU overcommute in the environment is 10:1 overcommitment which is the default setting. 

. You can adjust the time range going from 5 min to 1 week.
+
image::day-to-day/ob_select_vm.png[link=self, window=blank, width=100%]
+
. By the Network Transfer and Clicking Breakdown by network section you can see how much traffic is passing through in this space it only shows default because there is only one network adapter.
+
image::day-to-day/select_network.png[link=self, window=blank, width=100%]
+
. Click on CPU Usage bar graph
+
image::day-to-day/select_cpu.png[link=self, window=blank, width=100%]
+
. In the Metrics you see how the CPU spiked. here you can see over the last 30 minutes
+
image::day-to-day/cpu_metrics.png[link=self, window=blank, width=100%]
+
. You can change the interval time anywhere from 5 minutes to 2 weeks.
+
image::day-to-day/change_interval.png[link=self, window=blank, width=100%]
+
. Here you can change the refresh timing.
+
image::day-to-day/change_refresh.png[link=self, window=blank, width=100%]
+
. You can also add queries 
+
image::day-to-day/select_qurey.png[link=self, window=blank, width=100%]
+
. Lets add a query "sum(rate(kubevirt_vmi_vcpu_wait_seconds_total{name='winweb01',namespace='windows-vms'}[5m])) BY (name, namespace)" without the "". This query will show the amouont of time spent by each vcpu while waiting on I/O.
+
image::day-to-day/example_query.png[link=self, window=blank, width=100%]

==== Dashboards

. Click on *Observe* > *Dashboard*.
+
image::day-to-day/dashboard.png[link=self, window=blank, width=100%]
+
. Click on *API Performance* and search for *KubeVirt/Infrastructure Resources/Top Consumers*
+
image::day-to-day/kubevirt_dashboard.png[link=self, window=blank, width=100%]
+
. This dashboard you will see the top consumer for your virtual machines. Let dive in and look at the Top Consumers of CPU by virt-launcher Pods and Click *Inspect*
+
image::day-to-day/cpu_inspect.png.png[link=self, window=blank, width=100%]
+
. You can can select the VMs you want to see in the graph.
+
image::day-to-day/metrics_select.png[link=self, window=blank, width=100%]
+


== Horizontally Scale Front End

. For this part of the lab we need to make sure that the load maker pod is running

+
. Click on *Workloads* > *Deployments* > *loadmaker*. Ensure you are in Project: *windows-vms*.
+
image::day-to-day/select_loadmaker.png[link=self, window=blank, width=100%]
+
. You should see 1 Pod under the Deployment Details tab.
+
image::day-to-day/show_num_pod.png[link=self, window=blank, width=100%]
+
. Click on *Environment* tab
+
image::day-to-day/lm_pod_config.png[link=self, window=blank, width=100%]
+
. In *Virtualization* > *VirtualMachine* Select *windows-vms* project to show *winweb01*, *winweb02* and *database*. You should see high resource usage on *winweb01*.
+
image::day-to-day/before_upgrade_horizontally.png[link=self, window=blank, width=100%]
+
. Click on the checkbox next to *winweb02*, Click on *Actions* > *Start* to power on *winweb02*
+
image::day-to-day/power_on.png[link=self, window=blank, width=100%]
+
. After approximently 5 minutes the load will even itself out between both winweb servers.
+
image::day-to-day/vm_add_horizontally.png[link=self, window=blank, width=100%]

=== Vertically scale Backend

. Click on the *winweb01*.
+
image::day-to-day/select_vm.png[link=self, window=blank, width=100%]
+
. Click on the *Configuration* tab
+
image::day-to-day/select_config.png[link=self, window=blank, width=100%]
+
. In the VIrtualMachine Details under CPU | Memory section Click on *2 CPU | 1 Gib Memory*
+
image::day-to-day/edit_vm.png[link=self, window=blank, width=100%]
+
. Increase the vCPUs to 8 and Memory to 4 and Click Save
+
image::day-to-day/update_specs.png[link=self, window=blank, width=100%]
+
. Click back on the *Overview* tab. You will see that the CPU | Memory section in the details has been updated to the new values.
+
image::day-to-day/vm_new_spec.png[link=self, window=blank, width=100%]
+
. Repeat these steps for *winweb02*.

. Once both vms are upgraded in the project tree view click on *windows-vms* project. You will see that the CPU and Memory usage has gone down.
+
image::day-to-day/updated_usage.png[link=self, window=blank, width=100%]
+

=== Enable Swap/Memory Overcommit

== New gear arrives

=== Live Migrate Backend VMs (remove or tolerate node taint)
